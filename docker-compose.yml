version: '3.8'

services:
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "5050:5050"
    volumes:
      - ./backend/data:/app/data
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "7860:7860"
    environment:
      - BACKEND_URL=http://backend:5050
    depends_on:
      - backend
    restart: unless-stopped
